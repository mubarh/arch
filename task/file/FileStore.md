# Хранение файлов - статичные файлы [WIP]

## Описание задачи

Спроектировать систему для хранения и получения файлов (документы, фото, текст) разных компаний

Текущее кол-во компаний 10 (прогноз измнения: x3 в горизонте 5 лет)

### Use cases

* Разовая загрузка пачки файлов
* Правила обновления для каждого файла
* Оповещение клиента о потребности обновления файла
* Версионирование (обновление не удаляет предыдущее состояние файла)
* Возможность изменения в любой момент

Клиент

* иногда обновляет (меняют версию/версионируют)
* редко удаляют
* часто читают


### Ограничения

* Размер файлов: до 20mb
* Кол-во файлов: ~ (кол-во компаний) * 5000
* Время жизни: храним всегда
* Кол-во пользователей: ~ (кол-во компаний) * (120)
* Клиенты находятся в одной стране
* ~30 клиентов в сутки и каждый смотрит ~50 файлов
* Логика хоститься на наших серверах
* Клиенты смотрят разные файлы

### SLA (RPO (Recovery Point Objective) + RTO (Recovery Time Objective))

* Получать файл на просмотр в рамках 3 секунд


# Решение

## Требование по ресурсам

Для всей системы

* CPU:
  * Сервисов
  * Инфраструктуры
* Memory:
* Disk: 
  * По хранение файлов `20 * 30 * 5000 * 2 * 2 = 12TB`
    * 30 компаний
    * 5000 файлов
    * в два раза увеличится у каждой компании файлы через 5 лет
    * допустим что храним одну копию данных для сохранности (x2)
* Пропускная способность сети до клиента
  * на чтение файлов
    * 30 юзеров * 50 файлов * 30 компаний = 45000 файлов / день
    * `45000 * 20 ~= 900GB / день`
      * `~10 mb/s`
  * пренебрегаем расчетами на оповещение и изменение файлов


## Сетевой / Инфраструктурный слой

- Учесть, что система хранения увеличит объем хранения за счет служебных файлов
- Учесть, что нужна система, которая гарантирует, что мы не потеряем данные, даже в случае катастрофы
- Учесть, что нужна система, которая позволит в рамках 3 секунд отобразить файл клиенту 
- Учесть, что нужна отдельная система для хранения о пользователях и мета информации файлов

### Хранение

- Hadoop
- MongoDB
- Ceph
- Minio
- Postgres

#### Minio

- Для облачных решений
  - Имеет интеграцию с AWS/Hadoop/Teradata
  - Масштабируемая
  - Легко вкатывается в Kubernetes
  - Гипотетически мало кушает
- Много умеет прокачивать через себя

#### Hadoop (под вопросом)

- Заточен на надежность, а не на скорость
- Заточен под запись больших объемов (петабайты)
- Минимальный rfactor то на чтение уже сильно понижается скорость
- Большой размер блока по сравнению с другими файловыми системами (>64MB), поскольку HDFS предназначена для хранения большого количества огромных (>10GB) файлов; 
- Ориентация на недорогие и, поэтому не самые надежные сервера
- Сложно настроить

#### Ceph

- Похож на hadoop
- Уклон в отказоустойчивость
- Нет единой точки отказа
- Быстрее хадупа
- Для петабайт
- Есть S3
- Сложно настроить

#### MongoDB

- Есть GridFS, позволяет работать с файлами
- Мало отзывов о нем, кажется, что стоит использовать, только когда у тебя уже есть кластер монги

### Развертывание

- Kubernetes
- Nomad

## Компонентный / Сервисный слой

## Модель хранения данных